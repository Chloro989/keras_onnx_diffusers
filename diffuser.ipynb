{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvFI4UYdIeh_"
   },
   "source": [
    "# This is a very simple code to generate a image from text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute this cell to install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HL3rgXXT4RK",
    "outputId": "028ef9fe-c2a8-4483-9aa0-45061007bd1a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Module Stuff\n",
    "%cd \"~/Desktop/keras_onnx_diffusers\"\n",
    "!poetry update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput path confirmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chloro\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:65: UserWarning: Specified provider 'DmlExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "C:\\Users\\chloro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\clip\\feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chloro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\diffusers\\schedulers\\scheduling_pndm.py:118: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  torch.linspace(beta_start**0.5, beta_end**0.5, num_train_timesteps, dtype=torch.float32) ** 2\n",
      "C:\\Users\\chloro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_onnx_stable_diffusion.py:339: FutureWarning: `StableDiffusionOnnxPipeline` is deprecated and will be removed in version 1.0.0. Please use `OnnxStableDiffusionPipeline` instead of `StableDiffusionOnnxPipeline`.\n",
      "  deprecate(\"StableDiffusionOnnxPipeline\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Prompt Here Use Coron ->, to separate words: cat\n",
      "Enter the Number of Images You Want to Create:  1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter Prompt Here\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m     55\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use Coron ->, to separate words:\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[0;32m     56\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the Number of Images You Want to Create: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 57\u001b[0m \u001b[43mtext_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m, in \u001b[0;36mtext_to_image\u001b[1;34m(text, num_images_per_prompt)\u001b[0m\n\u001b[0;32m     30\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest quality,master piece,ultra detailed,4K quality,breathtaking,authentic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m text\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images_per_prompt):\n\u001b[1;32m---> 32\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnegative_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of iterations (controls image quality)\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                 \u001b[49m\u001b[43meta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Display each image\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_onnx_stable_diffusion.py:247\u001b[0m, in \u001b[0;36mOnnxStableDiffusionPipeline.__call__\u001b[1;34m(self, prompt, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, output_type, return_dict, callback, callback_steps)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected latents shape, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatents\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatents_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# set timesteps\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_timesteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m latents \u001b[38;5;241m=\u001b[39m latents \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39minit_noise_sigma)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# prepare extra kwargs for the scheduler step, since not all schedulers have the same signature\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# eta (η) is only used with the DDIMScheduler, it will be ignored for other schedulers.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# eta corresponds to η in DDIM paper: https://arxiv.org/abs/2010.02502\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# and should be between [0, 1]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\diffusers\\schedulers\\scheduling_pndm.py:186\u001b[0m, in \u001b[0;36mPNDMScheduler.set_timesteps\u001b[1;34m(self, num_inference_steps, device)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplms_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m][\n\u001b[0;32m    182\u001b[0m         ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    183\u001b[0m     ]\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# we copy to avoid having negative strides which are not supported by torch.from_numpy\u001b[39;00m\n\u001b[0;32m    185\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprk_timesteps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplms_timesteps])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimesteps \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime\n",
    "import os\n",
    "from PIL import Image\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import StableDiffusionOnnxPipeline\n",
    "\n",
    "# Check if directory exists\n",
    "if os.path.exists(\"output/\"):\n",
    "    print(\"ouput path confirmed\")\n",
    "else:\n",
    "    # Create directory\n",
    "    os.makedirs(\"output/\")\n",
    "\n",
    "# Height and Width\n",
    "H = 512\n",
    "W = 512\n",
    "\n",
    "# Set Pipe\n",
    "pipe = StableDiffusionOnnxPipeline.from_pretrained(\"model/stable_diffusion_onnx\", provider=\"DmlExecutionProvider\")\n",
    "\n",
    "# Negative Prompt\n",
    "NP = (\"NSFW,watermark,bad face,bad hand,bad face shape,extra hands,extra fingers,bad arm,extra arms,missing leg,detached arm,\"\n",
    "      \"inverted hand,ugly,bad eyes,logo,worst quality,blurry,bad anatomy,awful,separated,unpleasant quality\")\n",
    "\n",
    "# Text to Image\n",
    "def text_to_image(text,num_images_per_prompt=1):\n",
    "    text = \"best quality,master piece,ultra detailed,4K quality,breathtaking,authentic\" + text\n",
    "    for _ in range(num_images_per_prompt):\n",
    "        image = pipe(str(text),\n",
    "                     negative_prompt = NP,\n",
    "                     height= H, width= W,\n",
    "                     num_inference_steps = 96,  # Number of iterations (controls image quality)\n",
    "                     guidance_scale = 7.2,\n",
    "                     eta = 0.1,\n",
    "                     num_images_per_prompt = 1,\n",
    "                    ).images[0]\n",
    "    \n",
    "        # Display each image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # to hide the axis\n",
    "        plt.show()\n",
    "\n",
    "        # Save Image\n",
    "        pnginfo = PngInfo()\n",
    "        pnginfo.add_text('prompt', text)\n",
    "        image.save(\"output/\" + str(datetime.datetime.now().strftime('%Y%m%d%H%M%S%f')) + \".png\", pnginfo=pnginfo)\n",
    "        print(\"***\"\\\n",
    "             \" saved at 'output/' \"\\\n",
    "             \"***\")\n",
    "# Execution\n",
    "text = input(\"Enter Prompt Here\"\\\n",
    "             \" Use Coron ->, to separate words:\" )\n",
    "cnt = int(input(\"Enter the Number of Images You Want to Create: \"))\n",
    "text_to_image(text,num_images_per_prompt=cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make an Image into Black and White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tkinter import Button, Tk, filedialog\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def select_image():\n",
    "    filename = filedialog.askopenfilename(\n",
    "        filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")]\n",
    "    )\n",
    "    print(\"Selected:\", filename)\n",
    "\n",
    "    global selected_image\n",
    "    selected_image = filename\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "selected_image = None\n",
    "\n",
    "# ボタンを作成して配置する\n",
    "button = Button(root, text=\"Select Image\", command=select_image)\n",
    "button.pack()\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "\n",
    "# Load Image\n",
    "img = Image.open(selected_image)\n",
    "\n",
    "# NumPy配列を読み込む\n",
    "arr = np.array(img)\n",
    "\n",
    "# NumPy配列をPillowのImageオブジェクトに変換する\n",
    "img = Image.fromarray(np.uint8(arr))\n",
    "\n",
    "# Convert / 画像を白黒に変換\n",
    "img = img.convert(\"L\")\n",
    "\n",
    "# Save Image / 保存する\n",
    "img.save(\"images/\" + str(datetime.datetime.now().strftime(\"%Y%m%d%H%M%S%f\")) + \".png\")\n",
    "print(\"saved at image/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For Further Learning, Check Out the Links Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [**Official** Doc About Prompting @DreamStudio](https://beta.dreamstudio.ai/prompt-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [About Text to Image Using Diffusers @Huggingface](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [About keras_cv @GitGub](https://github.com/keras-team/keras-cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [**Japanese** Doc About How to Use Poetry](https://cocoatomo.github.io/poetry-ja/cli/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Find a Prompt Here @Lexica](https://lexica.art/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A Bit of Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "display(HTML('<h4>Using Old (like 100 years old) Artists Name Is Useful</h4>'))\n",
    "\n",
    "def plot_images(image_paths):\n",
    "    images = [np.array(Image.open(path)) for path in image_paths]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "display(HTML('<h5>Here are a Couple of Samples Made by Using the Name of Viktor Vansnetsov</h5>'))\n",
    "image_paths = [\"samples/sample1.png\",\"samples/sample2.png\"]\n",
    "plot_images(image_paths)\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>Interactive Div</title>\n",
    "    <style>\n",
    "        #content {\n",
    "            cursor: pointer;\n",
    "            color: white;\n",
    "            background-color: #007bff;\n",
    "            width: 600px;\n",
    "            height: 25px;\n",
    "            padding: 10px;\n",
    "            text-align: center;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "\n",
    "        #myframe {\n",
    "            display: none;\n",
    "            width: 600px;\n",
    "            height: 800px;\n",
    "        }\n",
    "    </style>\n",
    "\n",
    "    <script src=\"https://code.jquery.com/jquery-3.5.1.min.js\"></script>\n",
    "    <script>\n",
    "        $(document).ready(function(){\n",
    "            $(\"#content\").click(function(){\n",
    "                $(\"#myframe\").toggle();\n",
    "            });\n",
    "        });\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"content\">Click here to Check Viktor Vansnetsov's Wikipedia</div>\n",
    "    <iframe id=\"myframe\" src=\"https://en.wikipedia.org/wiki/Viktor_Vasnetsov\"></iframe>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "keras_onnx_diffusion",
   "language": "python",
   "name": "keras_onnx_diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
